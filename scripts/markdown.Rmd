---
title: "Prevendo Demanda de Estoque com Base em Vendas"
output:
  html_document:
    code_folding: hide
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Sobre

Projeto com feedback 02 do curso Big Data Analytics com R e Microsoft Azure Machine da Formação Cientista de Dados da Data Science Academy.

Dataset disponibilizado no kaggle pelo grupo Bimbo no desafio Grupo Bimbo Inventory Demand - Maximize sales and minimize returns of bakery goods.

Link do dataset: https://www.kaggle.com/c/grupo-bimbo-inventory-demand

Objetivo: Construir um modelo de machine learning para prever com precisão a demanda de estoque com base nos dados históricos de vendas.

## Baixando pacotes necessários

```{r pacotes, message = F}

library(kableExtra)
library(data.table)
library(stringr)
library(dplyr)
library(naniar)
library(ggplot2)
library(gridExtra)
library(psych)
library(ggcorrplot)
library(randomForest)
library(RColorBrewer)

```

## Amostra Dataset Principal

```{r carregamento_amostra}

df <- fread('train.csv')
df <- as.data.frame(df)

cliente <- read.csv('cliente_tabla.csv', sep = ',', header = T, stringsAsFactors = F)

produto <- read.csv('producto_tabla.csv', sep = ',', header = T, stringsAsFactors = F)

local <- read.csv('town_state.csv', sep = ',', header = T, stringsAsFactors = F)

head(df) %>%
    kbl(caption = 'Amostra - Dataset Principal') %>%
    kable_paper('striped',full_width = F) %>%
    row_spec(0, bold = T) %>%
    footnote('Grupo Bimbo - Prevendo Estoque')

```

## Dicionário de dados

```{r dicionario}

dic <- data.frame(variavel = c('Semana', 'Agencia_ID', 'Canal_ID',
                               'Ruta_SAK', 'Cliente_ID', 'NombreCliente',
                               'Producto_ID', 'NombreProducto',
                               'Venta_uni_hoy', 'Venta_hoy',
                               'Dev_uni_proxima', 'Dev_proxima',
                               'Demanda_uni_equil'),
                  descricao = c('número do dia da semana', 'ID do depósito de vendas',
                                'ID do canal de vendas', 'ID da rota', 'ID do cliente',
                                'nome do cliente', 'ID do produto', 'nome do produto',
                                'quantidade de vendas da semana',
                                'valor do total de vendas da semana',
                                'unidades retornadas próxima semana',
                                'valor do total retornados próxima semana',
                                'valor da demana (variável target)'),
                  tipo = c('inteiro', 'inteiro', 'inteiro', 'inteiro', 'inteiro', 
                           'string', 'inteiro', 'string', 'inteiro', 'double',
                           'inteiro', 'double', 'fator'),
                  valores_permitidos = c('números', 'números', 'números', 'números',
                                         'números', 'texto', 'números', 'texto',
                                         'números', 'valores numéricos', 'números',
                                         'valores numéricos', 'números'))

dic %>%
    rename('Variável' = variavel,
           'Descrição' = descricao,
           'Tipo de dado' = tipo,
           'Valores permitidos' = valores_permitidos) %>%
    kbl() %>% kable_paper('striped',full_width = F) %>%
    row_spec(0, bold = T)

```

## Pré-processamento de dados

### Alterando variáveis categóricas

(Agencia_ID, Canal_ID, Ruta_SAK, Cliente_ID, Producto_ID)

``` {r fatores}

fatores <- c('Agencia_ID', 'Canal_ID', 'Ruta_SAK', 'Cliente_ID', 'Producto_ID')
for (i in colnames(df)) {
    if (i %in% fatores) {
        df[,i] <- as.factor(df[,i])
    }
}

```

### Datas - criando coluna com nome e transformando em fator

(Segunda à Sexta - 1 à 7)

```{r datas, results = F}
memory.limit(9999999999)
df$Semana_Ext <- factor(df$Semana, labels = c("quinta", "sexta", "sábado", "domingo",
                                              "segunda", "terça", "quarta"))
df$Semana <- as.factor(df$Semana)

```

### Dataset Cliente - alterando coluna de fator e apresentando amostra

```{r cliente}

cliente$Cliente_ID <- as.factor(cliente$Cliente_ID)

head(cliente) %>%
  kbl(caption = 'Amostra - Dataset de Cliente') %>%
  kable_paper('striped',full_width = F) %>%
  row_spec(0, bold = T) %>%
  footnote('Grupo Bimbo - Prevendo Estoque')

```

### Dataset Produto - alterando coluna de fator e apresentando amostra

```{r produto}

produto$Producto_ID <- as.factor(produto$Producto_ID)

head(produto) %>%
  kbl(caption = 'Amostra - Dataset de Produto') %>%
  kable_paper('striped',full_width = F) %>%
  row_spec(0, bold = T) %>%
  footnote('Grupo Bimbo - Prevendo Estoque')

```

### Dataset Local - alterando coluna de fator, acertando nome de país e apresentando amostra

(MÃ‰xico - México)

```{r local}

local$Agencia_ID <- as.factor(local$Agencia_ID)
local$State <- str_replace_all(string = local$State, pattern = 'Ã‰', replacement = 'é')
local$State <- as.factor(local$State)

head(local) %>%
  kbl(caption = 'Amostra - Dataset de Local') %>%
  kable_paper('striped',full_width = F) %>%
  row_spec(0, bold = T) %>%
  footnote('Grupo Bimbo - Prevendo Estoque')

```

### Redução do dataset

Tendo em vista a lentidão nas etapas de pré-processamento proporcionada pelo tamanho do dataset, optei por trabalhar uma amostra do mesmo para que não ocorram demoras e/ou problemas na análise exploratória e no treinamento do algoritmo

```{r amostra}

df_amostra <- df[sample(1:nrow(df), 100000),]

```

### União de datasets
A fim de montar um dataset único de trabalho, realizei os joins de acordo com as chaves (Cliente_ID, Producto_ID, Agencia_ID)

``` {r join}

df_geral <- df_amostra %>%
    inner_join(cliente, by = 'Cliente_ID') %>%
    inner_join(produto, by = 'Producto_ID') %>%
    inner_join(local, by = 'Agencia_ID')

head(df_geral) %>%
  kbl(caption = 'Amostra - Dataset Final') %>%
  kable_paper('striped',full_width = F) %>%
  row_spec(0, bold = T)

```

### Data Missing
Abaixo podemos ver que o dataset final de trabalho não apresenta nenhum dado faltante

```{r missing}

gg_miss_which(df_geral) + 
    labs(title = 'Missing Data - Bimbo Inventory Demand',
         caption = 'Black = No missing Data') +
    theme(plot.title = element_text(hjust = 0.5))

```


## Análise Exploratória de Dados

Histogramas de vendas e devoluções - Qual é a quantidade de itens vendidos e devolvidos mais recorrente?

```{r histogramas, warning = F, message = F}

ven_hist <- df_geral %>%
    filter(Venta_uni_hoy >= 0)  %>%
    ggplot(aes(Venta_uni_hoy)) + geom_histogram(fill = '#543005') +
    scale_x_continuous(limits = c(0, 100),
                       breaks = seq(0, 100, 10)) +
    xlab('itens vendidos') + ylab(NULL)

dev_hist <- df_geral %>%
    filter(Dev_uni_proxima >= 0)  %>%
    ggplot(aes(Venta_uni_hoy)) + geom_histogram(fill = '#543005') +
    scale_x_continuous(limits = c(0, 100),
                       breaks = seq(0, 100, 10)) +
    xlab('itens devolvidos') + ylab(NULL)

grid.arrange(ven_hist, dev_hist, ncol = 1, nrow = 2, top = 'Histogramas de quantidades de vendas e devoluções')

```

As quantidades vendidas e devolvidas não divergem muito, ficando em sua maioria entre 3 e 15 unidades.

Quantidade de vendas e devoluções por agencia (top10)

```{r agencia_top10, message = F}

ven_agencia <- df_geral %>%
    group_by(Agencia_ID) %>%
    summarise(qtd = sum(Venta_uni_hoy)) %>%
    slice_max(qtd, n = 10) %>%
    ggplot(aes(x = reorder(Agencia_ID, -qtd), y = qtd)) +
    geom_col(fill = '#8C510A') +
    labs(subtitle = 'vendas') +
    xlab(NULL) + ylab(NULL)

dev_agencia <- df_geral %>%
    group_by(Agencia_ID) %>%
    summarise(qtd = sum(Dev_uni_proxima)) %>%
    slice_max(qtd, n = 10) %>%
    ggplot(aes(x = reorder(Agencia_ID, -qtd), y = qtd)) +
    geom_col(fill = '#8C510A') +
    labs(subtitle = 'devoluções') +
    xlab(NULL) + ylab(NULL)

grid.arrange(ven_agencia, dev_agencia, ncol = 1, nrow = 2, top = 'Top 10 - Agências que mais venderam e mais devolveram')

```

As agências que mais vendem não são as que mais devolvem. Da lista do top 10 de cada categoria, observamos que apenas a 2034 aparece nas duas, sendo a 7ª que mais vende e a 6ª que mais devolve.

Valor de vendas e devoluções por canais

```{r vendas_canais, message = F}

df_geral %>%
    group_by(Canal_ID) %>%
    summarise(valor = sum(Venta_hoy)) %>%
    slice_max(valor, n = 5) %>%
    rename('R$' = valor) %>%
    kbl(caption = 'Valor das vendas dos canais mais exitosos') %>%
    kable_paper('striped',full_width = F) %>%
    row_spec(0, bold = T)

df_geral %>%
    group_by(Canal_ID) %>%
    summarise(valor = sum(Dev_proxima)) %>%
    slice_max(valor, n = 5) %>%
    rename('R$' = valor) %>%
    kbl(caption = 'Valor das devoluções dos canais menos exitosos') %>%
    kable_paper('striped',full_width = F) %>%
    row_spec(0, bold = T)

```

Nos dois quadros acima observamos que os valores das vendas são muito maiores que os das devoluções.

Demanda por dia da semana

````{r demanda_dia, warning = F}

df_geral %>%
    ggplot(aes(x = Semana_Ext, y = Demanda_uni_equil)) +
    geom_boxplot(outlier.colour = '#BF812D', outlier.alpha = .5) +
    xlab(NULL) + ylab('Demanda') + ggtitle('Demanda por dia da semana') +
    scale_y_continuous(limits = c(0, 1000),
                       breaks = seq(0, 1000, 200)) +
    theme(plot.title = element_text(hjust = 0.5))

```

A demanda diária parece seguir o mesmo padrão e a mesma média, com alguns outliers (atentar sábado e domingo) que podem ser relevantes.

Correlação de Variáveis

```{r correlacao}

df_cor_temp <- df_geral

df_cor_temp$Semana <- as.numeric(df_cor_temp$Semana)
df_cor_temp$Agencia_ID <- as.numeric(df_cor_temp$Agencia_ID)
df_cor_temp$Canal_ID <- as.numeric(df_cor_temp$Canal_ID)
df_cor_temp$Producto_ID <- as.numeric(df_cor_temp$Producto_ID)

df_cor <- round(cor(df_cor_temp[,c(1:3, 6:11)]), 1)

ggcorrplot(df_cor, title = 'Correlação de Variáveis', legend.title = NULL,
           colors = c("#543005", "#C7EAE5", "#003C30")) +
    theme(plot.title = element_text(hjust = 0.5))

```

É possível observar que a única coluna categórica que demonstra fraca correlação com as demais numéricas é a variável Canal_ID.
As variáveis numéricas apresentam médias e fortes correlações entre si.

## Processo de Machine Learning

### Separação de datasets de treino e teste

O dataset de trabalho é o de treino, vamos baixar o de teste para realização das previsões:

```{r teste}

teste <- fread('test.csv')

```

### Treinamento do algoritmo

#### Modelo 1 - Regressão linear

Conforme visto, além das variáveis numéricas, a única categórica que parece ter alguma relação e/ou influência no conjunto de dados é a Canal_ID.

Por isso, além das numéricas, vamos utilizá-la na primeira versão do nosso modelo:

``` {r modelo1}

modelo1 <- lm(Demanda_uni_equil ~ Venta_uni_hoy + Venta_hoy + Dev_uni_proxima + Dev_proxima + Canal_ID, data = df_geral)

```

#### Previsão

```{r previsao1}

previsao1 <- predict(modelo1, data = teste)

```

#### Análises

```{r resumo1}

summary(modelo1)

```

- Variáveis com muitos asterísticos - a análise exploratória foi bem sucedida e ajudou a pré selecionar variáveis relevantes para o modelo como, por exemplo: Venta_uni_hoy, Venta_hoy e Dev_uni_proxima.

- Multiple R-Squared altíssimo - muito próximo de 1, indicando alto nível de precisão

- p-value baixo, indicando a alta probabilidade das variáveis serem relvantes para o modelo

```{r score1, message = F}

score1 <- data.frame(atual = df_geral$Demanda_uni_equil,
                    previsao = previsao1)

ggplot(score1, aes(x = atual, y = previsao1)) + 
    geom_point(color = '#80CDC1') +
    geom_smooth(method = 'lm', color = '#543005') +
    labs(title = 'Linear Model - Atual x Previsão',
         x = 'Valores atuais',
         y = 'Valores Previstos') +
    theme(plot.title = element_text(hjust = 0.5))

```

No gráfico também podemos observar a ótima performance do modelo, onde os valores previstos se alteram de forma bastante discreta dos valores atuais.

#### Modelo 2 - Random Forest

```{r modelo2}

modelo2 <- randomForest(Demanda_uni_equil ~ Venta_uni_hoy + Venta_hoy + Dev_uni_proxima + Dev_proxima + Canal_ID, data = df_geral)

```

#### Previsão

```{r prevsao2}

previsao2 <- predict(modelo2, data = teste)

```

#### Análises

```{r resumo2}

print(modelo2)

```


```{r score2, message = F, warning = F}

score2 <- data.frame(dia_da_semana = df_geral$Semana_Ext,
                     atual = df_geral$Demanda_uni_equil,
                     previsao = previsao2)
score2 %>%
    group_by(dia_da_semana) %>%
    summarise(qtd1 = sum(atual),
              qtd2 = sum(previsao)) %>%
    ungroup() %>%
    ggplot() + 
    geom_line(aes(x = dia_da_semana, y = qtd1, group = 1), color = '#BF812D') +
    geom_line(aes(x = dia_da_semana, y = qtd2, group = 1), color = '#35978F') +
    labs(title = 'Random Forest - Atual x Previsão',
         x = NULL,
         y = NULL) +
    theme(plot.title = element_text(hjust = 0.5))

score2 %>%
    mutate(residuos = atual - previsao) %>%
    ggplot(aes(x = residuos)) +
    geom_histogram(binwidth = 1, fill = "#543005", color = "#8C510A") +
    scale_x_continuous(limits = c(-200, 400),
                       breaks = seq(-200, 400, 200)) +
    labs(title = 'Distribuição de Resíduos',
         x = 'Resíduos',
         y = NULL) +
    theme(plot.title = element_text(hjust = 0.5))

```

As linhas do primeiro gráfico mostram certa disparidade entre os valores atuais (linha marrom) e previstos (linha azul), porém, na distribuição dos resíduos, podemos ver que a maioria ficou em zero ou próximo de zero, levando ao entendimento que as diferenças entre valores atuais e previstos são nulos ou quase nulos.

O histograma nos fornece, também, a informação que a distribuição dos resíduos segue o formato de uma distribuição normal, dando indícios de um modelo com boa performance.

## Conclusão

Apesar do bom desempenho do random forest, o modelo de regressão linear simples resultou em altíssimo R-Squared e, ao mesmo tempo, baixo p-value, indicando que seria o melhor caminho para previsão das demandas.